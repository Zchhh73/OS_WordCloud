	操作系统的基本概念 
	批处理与多道程序设计
	简述多道程序设计的概念。
答：将一个以上的作业存放在主存中，并且同时处于运行状态，这些作业共享处理器、外设以及其它资源，各作业轮流使用CPU。
多道程序设计的特点有：多道、宏观上并行、微观上串行。
    多道：计算机内存中同时存放多道相互独立的程序。
    宏观上并行：同时进入系统的多道程序都处于运行过程中，即它们先后开始了各自的运行，但都未运行完毕。
    微观上串行：内存中的多道程序轮流占有CPU，交替执行。

	分时系统与实时系统
分时系统特征：多路性、独立性、及时性、交互性。
实时系统特征：多路性、独立性、及时性、交互性、可靠性。
	批处理操作系统、分时操作系统和实时操作系统各有什么特点？
答：批处理操作系统：用户脱机使用计算机，作业是成批处理的，系统内多道程序并发执行，交互能力差。
    分时操作系统：可以让多个用户同时使用计算机，人机交互性较强，具有每个用户独立使用计算机的独占性，系统响应及时。
    实时操作系统：能对控制对象作出及时反映，可靠性高，响应及时，但是资源利用率低。
	推动批处理系统和分时系统形成和发展的主要动力是什么？
答：批处理系统：“不断提高系统资源利用率”和“提高系统吞吐量”。
    分时系统：“为了更好地满足用户的需要”

	操作系统的基本类型与特征
	操作系统的基本特征有 并发性 、 共享性 、 虚拟性 和 异步性 。
	分布式操作系统的特征有： 分布性 、 并行性 、 共享性 、 透明性 和 健壮性 。
	在分时操作系统中，改善响应时间的方法是： 重入码 和 虚拟存储器 。
	在批处理兼分时的系统中，往往由分时系统控制的作业称为 前台 作业，而由批处理系统控制的作业称为 后台 作业。
	简述操作系统的定义。
答：操作系统是计算机系统的一种系统软件，它是控制和管理整个计算机系统的硬件和软件资源，并合理地组织调度计算机工作和资源的分配，以提供给用户和其它软件方便的接口和环境的程序集合。
	什么是批处理操作系统？
答：用户准备好要执行的程序、数据和控制作业执行的说明书，由操作员输入到计算机系统中等待处理。操作系统选择作业并按作业说明书的要求自动控制作业的执行。采用这种批量化处理作业的操作系统称为批处理操作系统。
	为什么说多道批处理系统能极大地提高计算机系统的工作效率？
答：（1）多道作业并发工作，减少了处理器的空闲时间。
（2）作业调度可以合理选择装入内存中的作业，充分利用计算机系统的资源。
（3）作业执行过程中不再访问低速设备，而直接访问高速的磁盘设备，缩短执行时间。
（4）作业成批输入，减少了从操作到作业的交换时间。
	操作系统具有哪些基本特征？
答：（1）并发性。并发性是指两个或两个以上的活动在同一时间间隔内发生。
（2）共享性。共享性是指操作系统中的资源可被多个并发执行的进程所使用。
（3）虚拟性。虚拟性是指把一个物理上的实体变为若干个逻辑上的对应物。前者是实的，即实际存在的；而后者是虚的，是用户感觉上的东西。
（4）异步性。在多道程序环境下，系统允许多个进程并发执行，由于资源有限而进程众多，多数情况下，进程都是按“走走停停”的方式执行，即进程是以人们不可预知的速度向前推进的，这就是异步性。

	并发与并行的概念
并发：指两个或多个事件在同一时间间隔内发生。
并行：指两个或多个事件在同一时刻发生。

	操作系统的层次结构与功能模块
计算机层次从内到外依次为：裸机、CPU调度、内存管理、设备管理、文件管理、作业管理、命令管理、用户。
计算机系统的层次关系：计算机硬件、操作系统、其它系统软件、应用程序、用户。
	内核的基本功能是 中断处理 、 进程管理 、 资源的基本操作 。
	用户与操作系统的接口是： 命令接口 和 程序接口 。
	作业的控制方式有： 脱机作业控制 和 联机作业控制 。
	系统调用有五大类，它们是： 进程控制类 、 文件操作类 、 设备管理类 、 信息维护 和 通信系统 。
	采用客户/服务器模式构造一个操作系统的基本思想是，把操作系统划分为若干 进程 ，其中的每一个各实现单独的一种 服务 。
	中断处理程序的主要工作是： 保护现场 、 分析中断原因 和 处理发生的中断事件 ，在大多数情况下，中断处理程序往往简单处理完前两个工作后，就把具体的处理交给其它程序模块去做。
	UNIX的shell有两层含义，一是指由shell命令组成的 shell命令 语言；二是指 该命令的解释 程序。
	操作系统提供给应用程序的接口是 系统调用 。
	系统调用与一般过程调用有什么差别？
答：（1）运行在不同的系统状态，系统调用运行在管态而一般过程调用运行在用户态。
（2）系统调用通过软中断进入，先由用户态转为系统态，经核心分析后，才能转向相应的系统调用处理子程序。
（3）返回问题。在采用了抢占式调度方式的系统中，当调用进程仍具有最高优先级时，才返回到调用进程继续执行；否则，将引起重新调度，以便让优先权最高的进程优先执行。
（4）嵌套调用。一般过程调用可嵌套进行，系统调用也可以嵌套进行。
	处理器为什么要区分核心态和用户态两种操作方式？在什么情况下进行两种方式的切换？
答：区分执行态的主要目的是保护系统程序。用户态切换到核心态的转换发生在中断产生时，而核心态到用户态的转换则发生在中断返回用户程序时。

	程序的并发执行与顺序执行
	要达到并发进程执行结果的可再现性，可采用 Bernstein条件 实现。
	并发执行程序有三个特征，它们是： 间断性 、 失去封闭性 和 不可再现性 。
	若有两个进程P1和P2能并发执行，则Bernstein条件为： R(P1)∩W(P2)∪R(P2)∩W(P1)∪W(P1)∩W(P2)={  } 。
	当一个进程独占处理器顺序执行时，具有三个特性： 顺序性 、 封闭性 和 可再现性 。
	进程可以并发执行，若干个并发执行的进程交替占用处理器，而进程各种状态的转换不是事先预定的，也不是完全由操作系统来确定的，而是在硬件和操作系统的相互配合下完成的，起主要作用的是 中断系统 。

	处理机管理 
	进程: 进程控制块、进程的几种基本状态与状态转换（进程的创建、进程的终止、进程的阻塞与唤醒、进程的挂起与激活等）
进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。
进程的特征：
（1）动态性。进程是程序的一次执行。（最基本的特征）
（2）并发性。指多个进程实体，同存于内存中，且能在同一段时间内同时运行。
（3）独立性。指进程实体是一个能独立运行、独立获得资源和独立接受调度的基本单位。
（4）异步性。指进程按异步方式运行的，即按各自独立的、不可预知的速度向前推进。
（5）结构性。指每个进程都配置了一个PCB，从结构上看，进程实体由程序段、数据段和进程控制块组成。
进程控制块主要包含信息：
（1）进程标识符
     ①外部标识符 ②内部标识符
（2）处理机状态
     ①通用寄存器 ②指令计数器 ③程序状态字PSW ④用户栈指针
（3）进程调度信息
     ①进程状态 ②进程优先级 ③进程调度所需的其它信息 ④事件
（4）进程控制信息
     ①程序和数据的地址 ②进程同步和通信机制 ③资源清单 ④链接指针
进程的创建：
引起事件：（1）用户登录（2）作业调度（3）提供服务（4）应用请求
创建过程：（1）申请空白PCB（2）分配运行所需资源（3）初始化PCB（标识信息、处理机状态信息、处理机控制信息）（4）进入就绪队列
进程的终止：
引起事件：（1）正常结束（2）异常结束（3）外界干预
终止过程：（1）取出PCB读出进程状态（2）若进程处于执行状态，终止执行，置调度标志为真。（3）若有子孙进程，将子孙进程全部终止。（4）归还全部资源（5）将PCB从所在队列移除。
进程的阻塞与唤醒：
引起事件：（1）向系统请求共享资源失败（2）等待某种操作完成（3）新数据尚未到达（4）等待新任务到达
阻塞过程：（1）停止执行（2）更改PCB状态为阻塞（3）将PCB插入阻塞队列（4）重新调度
唤醒过程：（1）将PCB移出阻塞队列（2）更改PCB状态为就绪（3）将PCB插入就绪队列
进程的挂起与激活：
挂起过程：（1）检查进程状态，若处于活动就绪状态，则改为静止就绪；若处于活动阻塞状态，则改为静止阻塞；若处于执行状态，则重新调度（2）为了方便考查进程运行情况，将PCB复制到某指定内存区域
激活过程：（1）检查进程状态，若处于静止就绪，则改为活动就绪；若处于静止阻塞，则改为活动阻塞（2）若为抢占调度策略，检查是否要进行重新调度
	操作系统中，进程可以分为 系统 进程和 用户 进程两类。
	从结构上说，任一进程均由三部分组成，这三个组成部分分别是 进程控制块 、 程序段 和 数据段 。
	请描述在当前运行进程状态改变时，操作系统进行进程切换的步骤。
答：（1）保存当前进程上下文环境。
（2）对当前运行进程的PCB进行更新，并将其移入适当的队列。
（3）选择其它进程执行。
（4）对选择进程PCB进行更新，包括将其状态改为运行。
（5）对存储器管理数据结构进行更新。
（6）恢复被选择进程上次移出时的处理器状态。
	什么叫原语？什么叫原子操作？怎样保证原子操作？
答：原语是由若干机器指令构成用以完成特定功能的一段程序，并且在执行中不可分割。
原子操作是在一个操作中的所有动作，要么全做，要么全不做。
在单机中采用屏蔽中断可保证原子性，在多机系统可采用信号量机制保证原子性。
	进程的定义是什么？它最少有哪几种状态？
答：进程是一个具有一定独立功能的程序关于某个数据集合的一次运行活动。一个进程最少有就绪、执行和阻塞3种状态。
	在操作系统中为什么要引入进程的概念？会产生怎样的影响？
答：为了实现多个程序的并发执行。传统的程序不能与其它程序并发执行，只有在为其创建进程后才能与其它程序并发执行。这是因为并发执行的程序是“停停走走”地执行，只有在为其创建进程后，在停下时才能将其现场信息保存在它的PCB中，待下次被调度执行时再从PCB中恢复CPU现场并继续执行。
建立进程使多个程序能并发执行，极大地提高了资源利用率和系统吞吐量。但管理进程也需要付出一定代价，包括PCB和协调各运行机构所占用的内存空间开销，以及为进程间的切换、同步和通信等所付出的时间开销。

	进程的同步与互斥：临界资源、临界区、进程同步与互斥问题、信号量机制以及P、V操作、管程机制。
临界资源：同时仅允许一个进程使用的资源。许多物理设备都属于临界资源，如打印机等。
临界区：每个进程中访问临界资源的那段代码。（进入区、临界区、退出区、剩余区）
	一个操作中的所有动作，要么全做，要么全不做，这叫做 原子操作 。
	AND机制能实现系统的 安全性 ，并能防止 死锁 出现。
	采用 信号量机制 能保证程序的偏序执行。
	引起进程相互制约的两类原因是： 互斥使用资源 和 进程间相互合作 。
	互斥与同步解决方法有 软件方法 、 中断方法 、 Test-and-Set指令 、 Swap指令 和 信号量方法 。
	请解释进程同步机制中的让权等待的概念，并说明为什么要采用让权等待。
答：进程同步机制中的让权等待的概念是：当进程不能获得资源时，放弃处理机，避免忙等。采用让权等待，主要是为了更有效地发挥CPU的效能，提高系统的吞吐量。
	试写出P（S）操作的主要操作步骤。
答：（1）S = S – 1（S为信号量）。
（2）若S < 0，阻塞当前进程，将其插入S的等待队列，调度另一进程运行。
（3）若S >= 0，当前进程继续运行。
	试写出V（S）操作的主要操作步骤。
答：（1）S = S + 1（S为信号量）。
（2）若S <= 0，唤醒第一个等待该资源的进程，当前进程继续运行。
（3）若S > 0，当前进程继续运行。
	阐述对于互斥临界区的管理要求。
答：为实现进程互斥，可利用软件方法，也可在系统中设置专门的同步机制来协调各进程，但所有的同步机制都应遵循下述4条规则：（2分）
（1）空闲让进（1分）。无进程处于临界区时，相应的临界资源处于空闲状态，因而可允许下个请求进入临界区的进程立即进入自己的临界区，以有效地利用临界资源。
（2）忙则等待（1分）。已有进程进入自己的临界区时，相应临界资源正被访问，所有其它试图进入临界区的进程必须等待，以保证各进程互斥地访问临界资源。
（3）有限等待（1分）。对要求访问临界资源的进程，应保证该进程能在有效时间内进入自己的临界区，以免陷入“死等”状态。
（4）让权等待（1分）。当进程不能进入自己的临界区时，应立即释放处理机，以免进程陷入“忙等”。
	什么叫进程同步和互斥？举例说明。
答：进程同步是在几个进程合作完成一项任务时，体现各进程相互联系、协调的关系。例如：A、B两个进程合作通过缓存区输出数据。
把两个以上进程不能同时访问临界区的工作规则称为进程互斥。
例如：两个进程同时使用打印机。
	何为管程？管程由几部分组成？说明引入管程的必要性。
答：当共享资源用共享数据结构表示时，资源管理程序可用对该数据结构进行操作的一组过程来表示，如资源的请求和释放过程。把这样一组相关的数据结构和过程一并归为管程。
    管程由四部分组成：
    （1）管程的名称
    （2）局部于管程的共享数据结构说明
    （3）对该数据结构进行操作的一组过程
    （4）对局部于管程的共享数据设置初始值的语句
    管程的引入是为了解决临界区分散所带来的管理和控制问题。在没有管程之前，对临界区的访问分散在各个进程之中，不易发现和纠正分散在用户程序中的不正确地使用P、V操作等问题。管程将这些分散在各进程中的临界区集中起来，并加以控制和管理，管程一次只允许一个进程进入管程内，从而既便于系统管理共享资源，又能保证互斥。

	进程间通信：进程通信的类型（直接通信和间接通信方式）、消息传递系统中的几个问题、消息缓冲队列通信机制。
直接通信方式：指发送进程利用OS所提供的发送原语，直接把消息发送给目标进程。
间接通信方式：指发送和接收进程，都通过共享中间实体（称为信箱）的方式进行消息的发送和接收，完成进程间的通信。
	高级通信方式有： 共享存储器系统 、 消息传递系统 和 管道通信系统 。
	进程之间有哪些基本的通信方式？它们分别有什么特点？适用于哪些场合？
答：进程通信根据交换信息量的多少分为高级通信和低级通信。
    低级通信一般只传送一个或几个字节的信息，以达到控制进程执行速度的作用（如PV操作）；高级通信则要传送大量数据，目的是为了交换信息。
    高级进程通信方式有很多种，大致可归并为三类：共享存储器、管道通信和消息传递。
    共享存储器：在内存中分配一片空间作为共享存储区，需要进行通信的进程把它附加到自己的地址空间中，不需要时则把它取消。
    管道通信：它建立连接两个命令的一个打开文件，一个命令向该文件中写入数据，为写者；另一个命令从该文件中读出数据，为读者。
    消息传递：它以消息为单位在进程间进行数据交换。
	试说明进程互斥、同步和通信三者之间的关系。
答：进程的同步与互斥是指进程在推进时的相互制约关系。在多道程序系统中，由于资源共享与进程合作，这种进程间的制约成为可能。为了保证进程的正确运行以及相互合作的进程之间交换信息，需要进程之间的通信。
    进程之间的制约关系体现为：进程的同步和互斥。
    进程同步：它主要源于进程合作，是进程间共同完成一项任务时直接发生相互作用的关系，为进程之间的直接制约关系。在多道环境下，这种进程间在执行次序上的协调是必不可少的。
    进程互斥：它主要源于资源共享，是进程之间的间接制约关系。在多道系统中，每次只允许一个进程访问的资源称为临界资源，进程互斥就是保证每次只有一个进程使用临界资源。
    进程通信是指进程间的信息交换。PV操作作为进程的同步与互斥工具因信息交换
量少，效率太低，称为低级通信；而高级通信则以较高的效率传送大批数据。
	为什么进程之间的通信必须借助于操作系统内核功能？
答：每个进程有自己独立的地址空间，在操作系统和硬件的地址保护机制下，进程无法访问其它进程的地址空间，所以必须借助于操作系统的系统调用函数实现进程之间的通信。
	消息缓冲通信技术是一种高级通信机制，由Hansen首先提出。请回答下列问题。
（1）试叙述高级通信机制与低级通信机制P、V原语操作的主要区别。
（2）给出消息缓冲机制（有限缓冲）的基本工作原理。
（3）消息缓冲机制（有限缓冲）中提供发送原语Send(Receiver a)，调用参数a表示发送消息的内存区首地址。试设计相应的数据结构，并用P、V操作实现Send原语。
答：（1）P、V操作是指进程之间通过共享变量实现信息传递；而高级通信机制是由系统提供发送（Send）与接收（Receive）两个操作，进程间通过这两个操作进行通信，无须共享任何变量。
    （2）基本原理：操作系统管理一个用于进程通信的缓冲池，其中的每个缓冲区单元可存放一条消息。发送消息时，发送者从中申请一个可用缓冲区，接收者取出一条消息时再释放该缓冲区，每个进程均设置一条消息队列，任何发送给该进程的消息均暂存在其消息队列中。
    （3）缓冲区格式说明：Sptr指示该消息的发送者，Nptr指向消息队列中下一缓冲区的指针，Text为消息正文。设置互斥信号量mutex（初值为1）与一个同步通信信号量Sm（初值为0），Sm也用于记录消息队列中现存消息的数目。
         Send(a)操作如下：
         Send(a)
	{
		New(P);
		P.Sptr = address of the sender;
		Move message to buffer P;
		Find the receiver;
		P(mutex);
		add buffer P to the message queue;
		V(Sm);
V(mutex);
}

	线程与进程的调度:线程与进程的基本概念，调度的类型、调度队列模型、调度方式、进程调度算法（先来先服务、短进程优先、时间片轮转、基于优先级的调度算法等）。
线程是进程内一个相对独立的、可调度的执行单元。线程自己基本上不拥有资源，只拥有一点在运行时必不可少的资源（如程序计数器、一组寄存器和栈），但它可以与同属一个进程的其它线程共享进程拥有的全部资源。
调度的层次：高级调度（作业调度、长程调度）
中级调度（内存调度、中程调度、交换调度）
低级调度（进程调度、短程调度、微观调度）
进程调度方式：非剥夺调度方式（非抢占方式）
剥夺调度方式（抢占方式）
进程调度算法：先来先服务（FCFS）
              短进程优先（SPF）
              时间片轮转（RR）
              基于优先级
调度队列模型：
 
	选择进程调度算法的准则是什么？
答：一般选择算法要考虑如下一些原则：
    （1）处理器利用率
（2）系统吞吐量
（3）周转时间
（4）等待时间
（5）响应时间
	现今操作系统中申请CPU的基本单位是什么？申请除CPU之外的资源的基本单位是什么？
答：现今操作系统中，线程是系统进行处理器调度的基本单位，也就是说申请CPU的基本单位是线程；而申请除CPU之外的资源的基本单位仍然是进程。进程为线程提供运行资源并构成静态环境，引入线程机制后，同一个进程中的所有线程共享进程获得的主存空间和资源，操作系统可以在线程间进行快速切换，大大提高了系统的运行性能。
	列举引起进程调度的时机。
答：（1）执行中的进程执行完毕或因发生某事而不能再继续执行。
（2）执行中的进程因提出I/O请求而暂停执行。
（3）在进程通信或同步过程中执行了某种原语操作，如P操作、block原语、wakeup原语等。
（4）在可剥夺式调度中，有一个比当前进程优先权更高的进程进入就绪队列。
（5）在时间片轮转算法中，时间片用完。
	什么是多线程？多线程与多任务有什么区别？
答：多线程指一个程序中可以定义多个线程同时运行，每个线程可以执行不同的任务。
多线程是针对一个程序而言的，代表着一个程序可以同时执行的线程个数，而每个线程可以完成不同的任务。
多任务是针对操作系统而言的，代表着操作系统可以同时执行的程序个数。
	进程与线程的主要区别是什么？
答：进程和线程的主要区别如下：
    （1）调度方面。传统操作系统中，拥有资源和独立调度的基本单位是进程，而在引入线程的操作系统中，线程是独立调度的基本单位，进程是资源拥有的基本单位。在同一进程中，线程的切换不会引起进程切换。在不同的进程中进行线程切换，将会引起进程切换。
    （2）并发性。不仅进程之间可以并发执行，而且同一进程内的多个线程之间也可以并发执行。
（3）拥有资源。进程是拥有资源的基本单位，线程不拥有资源，但线程可以访问其隶属进程的系统资源。
（4）独立性。同一进程中的不同线程之间的独立性要比不同进程之间的独立性低得多。
    （5）系统开销。进程切换时，涉及整个当前进程CPU环境的保存以及新调度进程的CPU环境的设置；而线程切换时，只需保存和设置少量寄存器内存，因此开销小。另外，由于同一进程的多个线程共享进程的地址空间，因此多线程之间的同步与通信非常容易实现。
	为什么说多级反馈队列调度算法能较好地满足各类用户的需要？
答：对终端型作业用户而言，他们提交的大多属于交互型作业，作业通常比较短小，系统只要能使这些作业在第1级队列所规定的时间片内完成，便可使终端型作业用户感到满意。
    对短批处理作业用户而言，他们的作业开始时像终端型作业一样，如果能在第1级完成，则可和终端型作业有一样的响应时间，对于稍长作业，通常也可在2、3级队列中执行完成，周转时间依然较短。
    对于长批处理作业而言，他们的长作业依次在1、2、…、n级队列中运行，然后再按时间片轮转方式运行，用户不必担心其作业长期得不到处理。

	死锁:死锁的基本概念，死锁定理、死锁预防、死锁避免与处理死锁的基本方法、银行家算法。
死锁定理：S为死锁状态的充分条件是，当且仅当S状态的资源分配图是不可完全简化的。
	产生死锁的原因： 竞争资源 和 进程的推进顺序不当 。
	什么是死锁？如何预防死锁？
答：死锁是因进程竞争资源或推进顺序不当而引发的一种胶着状态，即如果一组进程中的每一个进程都在等待仅由该组进程中的其它进程才能引发的事件，那么该组进程就是死锁的，若无外力作用，这种状态将永久保持下去。
	死锁的四个必要条件：互斥条件、请求和保持条件、不可抢占条件、循环等待条件。
	为了预防死锁，必须破坏死锁的四个必要条件。由于互斥条件一般不能改变，因此可以采取破坏四个必要条件的后三个。
	简述解决死锁问题的三种主要方法。
答：解决死锁的三种主要方法有：
    （1）死锁的预防。系统按预定的策略为进程分配资源，这些分配策略能使死锁的四个必要条件之一不成立，从而使系统不产生死锁。
    （2）死锁的避免。系统动态地测试资源分配情况，仅当能确保系统安全时才给进程分配资源。
    （3）死锁的检测。对资源的申请和分配不加限制，只要有剩余的资源就应把资源分配给申请者，操作系统要定时判断系统是否出现了死锁，当有死锁发生时设法解除死锁。
	按序分配是预防死锁的一种策略。什么是按序分配？为什么按序分配可以预防死锁？
答：按序分配即把系统的所有资源排一个顺序，例如，系统共有m个资源，用r_i表示第i个资源，于是这m个资源是：r_1 〖,r〗_2 〖,⋯,r〗_m。规定进程不得在占用资源r_i (1≤i≤m)后再申请r_j (j<i)。
可以证明，按这种策略分配资源时不会发生死锁。事实上，若在时刻t_1，进程P_1处于等待资源r_k1的状态，则r_k1必为另一进程P_2所占用。若进程P_2可以运行结束，则P_1就不会永远处于等待状态；所以一定在某个时刻t_2，进程P_2处于永远等待资源r_k2的状态。依此类推，假定系统只有有限个进程，则必定有某个时刻t_n，进程P_n处于永远等待资源r_kn的状态，而r_kn必为前面的进程P_1占用。于是，按照上面的按序分配策略，当P_2占用了r_k1后再申请r_k2，必有：k1<k2。依次类推，可得：k2<k3<…<kn。但是，进程P_n是占有r_kn申请r_k1，那么，必定有：kn<k1。这就产生了矛盾，所以按序分配策略可以预防死锁。

	综合应用：生产者消费者问题、读者和写者问题、哲学家进餐问题等。
	在哲学家就餐问题中，如果将先拿起左边筷子的哲学家称为左撇子，而将先拿起右边筷子的哲学家称为右撇子。在同时存在左撇子和右撇子的前提下，我们安排哲学家随意就座。请问是否可能产生死锁，为什么？
答：不可能产生死锁，它破坏了产生死锁的必要条件——“循环等待”。
    如果存在所有左边的哲学家等待右边哲学家放下筷子的循环等待，则每个哲学家肯定已获得左边的筷子，但还没有获得右边的筷子，这与存在右撇子的情况不符。同理，亦不存在相反的循环等待链，而且，因不相邻的哲学家之间不存在竞争资源关系，所以也不可能存在五个以下哲学家的循环等待链。
	什么是临界资源、死锁？若采用以下算法解决哲学家就餐问题，是否会导致死锁？为什么？
semaphore fork[5] = {1,1,1,1,1};
void main()
{
		cobegin{
			philosopher(0);
philosopher(1);
philosopher(2);
philosopher(3);
philosopher(4);
}coend
}

void philosopher(int i)
{
		while(1){
			thinking;
			if(i == 0){
				P(fork[i]);
				P(fork[(i + 1)%5]);
}else{
				P(fork[(i + 1)%5]);
				P(fork[i]);
}

eating;
V(fork[i]);
V(fork[(i + 1)%5]);
}
}

答：临界资源是同时仅允许一个进程使用的资源，即必须互斥使用的资源。许多物理设备都属于临界资源，如打印机等。
死锁是因进程竞争资源或推进顺序不当而引发的一种胶着状态，即如果一组进程中的每一个进程都在等待仅由该组进程中的其它进程才能引发的事件，那么该组进程就是死锁的，若无外力作用，这种状态将永久保持下去。
采用该算法不会导致死锁，因为它破坏了产生死锁的必要条件——“循环等待”。
设i号哲学家左边的筷子为i号，右边的筷子为(i + 1)%5号，则如果存在所有右边的哲学家等待左边哲学家放下筷子的循环等待，则每个哲学家肯定已获得右边的筷子，但还没有获得左边的筷子，这与程序中0号哲学家先拿取左边筷子的情况不符。同理，亦不存在相反的循环等待链，而且，因不相邻的哲学家之间不存在竞争资源关系，所以也不可能存在五个以下哲学家的循环等待链。

	内存管理
	内存管理的需求：重定位、内存保护、内存共享
内存保护：界限寄存器方法、存储保护键方法
	内存管理的主要功能有 内存的分配和回收 、 地址映射 、 存储保护 和 扩充内存 。
	利用 硬件中断 装置使得计算机操作系统可以控制各个程序的执行，为用户提供各种服务。主存储器是以 字节 为单位进行编址的。
	主存储器有多种管理方式，对不同的管理方式有不同的实现保护的方法，在每个程序占据主存连续空间的存储方式中，硬件设置两个寄存器： 基址寄存器 和 限长寄存器 ，用来限定用户程序执行时可以访问的主存空间范围。
	在存储器管理中，什么是重定位？为什么要引入重定位技术？
答：重定位就是将作业地址空间中的逻辑地址转换为主存中的物理地址，其实质为地址变换。因为源程序经过编译、链接产生的装入模块一般总是从0开始编址的，其中的地址都是相对于起始地址的相对地址（逻辑地址）。而在装入内存时，其分配到的内存的起始地址通常不是0。因此，指令和数据的实际物理地址与装入模块中的相对地址不同。为使程序能够正确运行，必须进行重定位。
	为什么要进行内存管理？
答：在单道批处理系统阶段，一个系统一个时间段内只执行一个程序，内存的分配极其简单，仅分配给当前运行进程即可。而引入了多道程序的并发执行之后，进程之间共享的不仅仅是处理机，还有主存储器。如果不对内存进行管理，容易导致内存数据的混乱，以至于限制进程的并发执行，所以为了更好地支持多道程序并发执行，必须要进行内存管理。

	程序的装入和链接：静态装入和可重定位装入、静态链接、动态链接、运行时动态链接。
编译：由编译程序将用户源代码编译成若干个目标模块。
链接：由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块。
装入：由装入程序将装入模块装入内存。
绝对装入方式：用户程序经编译后，将产生绝对地址的目标代码。装入模块被装入内存后，由于程序中的相对地址与实际内存地址完全相同，故不必对程序和数据的地址进行修改。
可重定位装入方式：用户程序编译形成的若干个目标模块，它们的起始地址从0开始，程序中的其它地址也都是相对于起始地址计算的。故要根据内存的具体情况将装入模块装入到内存的适当位置，并在进程装入时一次完成对目标程序中指令和数据地址的修改，即地址变换。
动态运行时的装入方式：装入程序把装入模块装入内存后，并不立即把装入模块中的逻辑地址转换为物理地址，而是等到程序真正要执行时才进行，此方式通常需要重定位寄存器支持。
静态链接：在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的可执行程序，以后不再拆开。
装入时动态链接：将用户源程序编译后所得到的一组目标模块，在装入内存时，采用边装入边链接的链接方式。
运行时动态链接:对某些目标模块的链接，是在程序执行中需要该目标模块时，才对它进行链接。其优点是便于修改和更新，便于实现对目标模块的共享。
	在程序的链接中， 静态链接 需要共享目标模块的拷贝，而 动态链接 不需要共享目标模块的拷贝。
	什么是动态链接？
答：动态链接指用户程序的各程序段不是在程序开始运行前就链接好，而是在程序装入或运行过程中，当发现要调用的程序未链接时，才进行链接。

	分区存储管理：分区方式（单一连续分区、固定分区、可变式分区）、分区分配算法（首次适应算法、循环首次适应算法、最佳适应法、最坏适应法等）。
单一连续分配：分为系统区、用户区。
优点：简单、无外部碎片，可采用覆盖技术，不需要额外的技术支持。
缺点：只能用于单用户、单任务的操作系统中，有内部碎片，存储器利用率极低。
固定分区：将用户内存空间划分为若干个固定大小区域，每个分区只装入一道作业。
优点：可用于多道程序系统最简单的存储分配，无外部碎片。
缺点：不能实现多进程共享一个主存区，利用率较低，有内部碎片。
可变式分区（动态分区）：在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。
首次适应算法：空间分区以地址递增的次序链接。分配内存时顺序查找，找到大小能满足要
求的第一个空闲分区。
优点：优先利用内存低地址部分的空闲分区，从而保留了高地址部分的大的空闲分区，无内部碎片。
缺点：由于低地址部分不断被划分，致使低地址留下许多难以利用的很小的空间，即外部碎片，而每次查找又都是从低地址部分开始的，这无疑增加了查找可用空间分区的开销。
循环首次适应算法（邻近适应、下次适应）：空闲分区以地址递增次序链接。分配时从上次查找结束的位置开始继续循环查找，找到大小能满足要求的第一个空闲分区。
优点：使空闲分区的分布更加均匀，减少了查找空闲分区的开销。
缺点：导致缺乏大的空闲分区。
最佳适应算法：空闲分区以容量递增的次序链接，找到第一个能满足要求的空闲分区。
优点：总能分配给作业最恰当的分区，并保留大的分区。
缺点：导致产生很多难以利用的碎片空间，即外部碎片。
最差适应算法（最大适应）：空闲分区以容量递减的次序链接，找到第一个能满足要求的空
闲分区，也就是挑选出最大的分区。
优点：使分给作业后剩下的空闲分区比较大，足以装入其它作业。
缺点：由于最大的空闲分区总是因首先分配而被划分，当有大作业到来时，其存储空间的申请会得不到满足。
	在存储管理方案中，可用上、下限寄存器实现存储保护的是 分区式存储管理 。
	早期个人计算机的存储管理一般采用 单用户连续存储 管理方式。
	由固定分区发展为分页存储管理方式的主要推动力是 提高内存利用率 ；由分页系统发展为分段系统，进而又发展为段页式系统的主要动力分别是： 满足用户需要 和 既满足用户需要，又提高内存利用率 。
	在内存管理中，内部碎片和外部碎片各指的是什么？在固定式分区管理、可变式分区分配、页式虚拟存储系统、段式虚拟存储管理中，各会存在何种碎片？为什么？
答：内部碎片：指已经被分配出去却不能被利用的内存空间。
    外部碎片：指还没有被分配出去，但因其太小而无法分配给申请内存空间的新进程的内存空闲区域。
    固定分区管理：存在内部碎片。因为固定分区管理的每一个分区大小固定且分配给指定的进程，所以整个分区都属于一个进程，但如果进程比分区小，就会留下无法利用的内存空间。
    可变式分区分配：存在外部碎片。因为每个分区大小不固定，所以不可能分配给一个进程多余的空闲区域，但是由于进程需要一段连续的空闲区域，而内存中小的空闲区域可能满足不了进程的需求，就成了无法分配出去的外部碎片。
    页式虚拟存储系统：存在内部碎片。因为页的大小是固定的，每个进程的大小不会都刚好是页大小的整数倍，所以进程的最后一页往往都会存在一些已经分配给该进程但无法利用的空间。
    段式虚拟存储管理：存在外部碎片。因为一个段的分配需要连续的区域，而段长又不固定，所以内存中会存在一些小的空闲区域不能分配给任何一段，就成了无法分配出去的外部碎片。
	动态分区和固定分区分配方式相比，是否解决了碎片问题？
答：动态分区和固定分区分配方式相比，内存空间的利用率要高些。但是，总会存在一些分散的较小空闲分区，即外部碎片，它们存在于已分配分区之间，不能充分利用。可 以采用拼接技术加以解决。固定分区分配方式存在内部碎片，无外部碎片；动态分区分配方式存在外部碎片，无内部碎片。

	段式管理与页式管理：段、页、碎片等基本概念、段式管理与页式管理机制
分页存储管理系统地址变换机构：
 
分段存储管理系统地址变换机构：
 
	解释页式存储管理中为什么要设置页表和快表。
答：页式存储管理首先把主存储器分成大小相等的物理块，作为主存分配的物理单位，同时要求程序逻辑地址也分成与块大小一致的页面，这样就可以把作业信息按页面存放在块中。进行存储分配时，根据作业大小，确定其页面数，在装入主存时给它分配相应数目的物理块。这些物理块可以不相邻，为了在作业执行过程中准确地查找逻辑地址与绝对地址的对应关系，系统为每个作业建立一张页表，指出逻辑地址中的页号与物理块中的块号的对应关系。
    页表一般存放在主存储器中，当要按给定的逻辑地址进行读/写时，必须两次访问主存，延长了指令的执行周期，降低了执行速度，为了提高存取速度，系统设置了一个小容量的高速缓冲存储器，利用高速缓冲存储器存放页表的一部分，这部分页表即“快表”，利用快表可以一次访问主存完成读/写，大大缩短地址转换时间，从而提高查找速度和执行指令速度。
	阐述基本分页存储管理和请求分页存储管理的异同之处。
答：在基本分页存储管理系统中，系统将每个程序按固定的大小分成若干页，每页对应一个物理块号，程序的所有页面都被装入到内存当中。
    在请求分页存储管理系统中，程序仍然被系统分成若干页，但并不是所有的页面都被装入到系统中，而仅仅装入程序运行所必须的页面。当需要某一个页面时，再请求从外部调入，如果没有空闲的空间，则利用置换技术进行页面的淘汰和置换。
	在分页存储管理系统中，页表的主要作用是什么？现代大多数计算机系统都支持非常大的逻辑地址空间（2^32~2^64），这给页表设计带来了什么样的新问题，应如何解决。
答：页表的主要作用是记录进程的每个页面与对应的页框信息。
非常大的逻辑地址空间会导致进程的页表非常大，难以装入连续的地址空间。
为解决这个问题，可引入多级页表机制，即对页表进行分页，实现页表的离散存储，对离散分配的页表再建立页表。在此基础上，还可以引入虚拟存储技术，即将部分页表调入内存从而提高内存利用率。
	说明段页式系统存储分配的实现原理及图示其地址变换过程。
答：段页式系统存储分配原理：段页式系统既提供分段又提供分页，结合了两者的优点，即用分段方法来分配和管理地址空间，而用分页方法来分配和管理主存。在段页式系统中，用户的地址空间根据程序员的决定分成一些段，而每一段又分成固定大小的页。内存的划分和分页系统一样，也是划分成大小相等的块。这样从程序员的角度看，逻辑地址由段号和段内位移组成；从系统角度看，段内位移又可被看作页号和页内位移。
    地址转换如下图所示：
 

	虚拟内存：局部性原理、虚拟内存概念、请求分段与请求分页、段页式管理、段页式地址结构与地址转换、页面置换算法（先进先出、LRU、Clock置换）、抖动
局部性原理：大多数程序执行时，在一个较短的时间内仅使用程序代码的一部分，相应地，程序所访问的存储空间也局限于某个区域。
时间局部性：一条指令的一次执行和下次执行，一个数据的一次访问和下次访问，都集中在一个较短的时间内。
空间局部性：当前指令和邻近的几条指令，当前访问的数据和邻近的数据，都集中在一个较小的区域内。
页面分配策略：固定分配局部置换、可变分配全局置换、可变分配局部置换。
抖动（颠簸）：刚被淘汰的页面，过后不久又要访问，并且调入不久以后又调出，如此反复，使得系统把大部分时间用在了页面的调入调出上，而几乎不能完成任何有效的工作。
Belady异常：FIFO置换算法的缺页率可能会随着所分配的物理块数增加而增加的异常现象。
请求分页系统页表项：页号、物理块号、状态位P、访问字段A、修改位M、外存地址。
请求分段系统段表项：段号、段长、段基址、存取方式、访问字段A、修改位M、存在位P、增补位、外存地址。
请求分页中的地址变换过程：
 
请求分段中的地址变换过程：
 
请求分段中的缺段中断处理过程：
 
	对于请求分页管理系统中，提取页面的策略有： 请求调页策略 和 预调页策略 。
	操作系统中什么是虚拟存储器？为什么要引入虚拟存储技术？
答：在具有层次结构存储器的计算机系统中，自动实现部分装入和部分替换功能，能从逻辑上为用户提供一个比物理存储容量大得多，可寻址的“主存储器”，叫做虚拟存储器。虚拟存储区的容量与物理内存无关，而受限于计算机的地址结构和可用磁盘容量。
    计算机操作系统引入和使用虚拟存储技术的主要目的是提高系统的内存利用率和系统吞吐量。
	影响缺页中断率有哪几个主要因素？
答：影响缺页中断率的因素有四个：
    （1）页面大小。页面划分大，则缺页率较低；反之，缺页率较高。
    （2）进程所分配物理块的数目。所分配的物理块数目越多，缺页率越低；反之则越高。
    （3）页面置换算法。算法的优劣对缺页中断率影响很大，但不可能找到一种最佳算法。
    （4）程序固有特性。程序本身的编制方法对缺页中断率有影响，根据程序执行的局部性原理，程序编制的局部化程度越高，相应执行时间的缺页程度越低。以数组为例，如果每一行元素存放在一页中，则按行处理各元素缺页中断率低；反之，按列处理各元素，则缺页中断率高。
	虚拟存储器有哪些特征？简述之。
答：（1）离散性。指程序在内存中离散存储。
（2）多次性。指无需在作业运行时一次性地全部装入内存，而是允许被分成多次调入内存运行。
    （3）对换性。指无需在作业运行时一直常驻内存，而是允许在作业的运行过程中，进行换进和换出。
    （4）虚拟性。指从逻辑上扩充内存的容量，使用户所看到的内存容量，远大于实际的内存容量。
	在虚拟分页存储管理方案中，对于一个处于运行状态的进程，当CPU读取下一条指令时，发生缺页中断。操作系统要执行哪些操作以获得所需要部分的指令？
答：在页表中发现所要访问的页不在内存中，则产生缺页中断。操作系统接到此中断信号后，就调出缺页中断处理程序，根据页表中给出的外存地址，将该页调入内存，使作业继续运行下去。若内存中有空闲块，则分配一页，将新调入页装入内存，并修改页表中相应页表项驻留位及相应的内存块号。若此时内存中没有空闲块，则要淘汰某页。若该页在内存期间被修改过，则要将其写回至外存。
	覆盖技术与虚拟存储技术有何本质不同？交换技术与虚拟存储技术中使用的调入/调出技术有何相同与不同之处？
答：覆盖技术与虚拟存储技术最本质的不同在于覆盖程序段的最大长度要受内存容量大小的限制，而虚拟存储器中程序的最大长度不受内存容量限制，只受计算机地址结构的限制。另外，覆盖技术中的覆盖段由程序员设计，且要求覆盖段中各个覆盖具有相对独立性，不存在直接联系或相互交叉访问；而虚拟存储技术对用户的程序段之间没有这种要求。
    交换技术就是把暂时不用的某个程序及数据从内存移到外存中去，以便腾出必要的内存空间，或把指定的程序或数据从外存读到内存中的一种内存扩充技术。交换技术与虚存中使用的调入/调出技术的主要相同点是：都要在内存与外存之间交换信息。交换技术与虚存中使用的调入/调出技术的主要区别是：交换技术调入/调出整个进程，因此一个进程的大小要受内存容量大小的限制；而虚存中使用的调入/调出技术在内存和外存之间来回传递的是页面或分段，而不是整个进程，从而使得进程的地址映射具有了更大的灵活性，且允许进程的大小比可用的内存空间大。

	设备管理
	I/O系统的：基本概念、I/O控制方式（程序I/0、中断、DMA、通道）、相关数据结构、缓冲管理（单缓冲、双缓冲、循环缓冲、缓冲池）
使用特性：存储设备、I/O设备
信息交换单位：字符设备、块设备
传输速率：低速、中速、高速设备
共享属性：独占设备、共享设备、虚拟设备
I/O管理的功能：设备分配、设备处理、缓冲管理、设备独立性
I/O系统的层次结构：硬件、中断处理程序、设备驱动程序、设备独立性软件、用户层软件。
DMA控制器：命令/状态寄存器CR、内存地址寄存器MAR、数据寄存器DR和数据计数器DC。
程序I/O方式：CPU不断测试I/O设备是否完成，这种方式也称为轮询或忙等。
优点：简单易于实现，不需要很多硬件支持。
缺点：CPU和I/O设备只能串行工作，CPU利用率相当低。
中断驱动方式：输入数据时，CPU可以做其它工作。当输入完成时，设备控制器向CPU发出一个中断信号，CPU接收到中断信号之后，转去执行设备中断处理程序。
优点：CPU和I/O设备可以并行工作，提高了CPU利用率。
缺点：每一个数据都会要求中断，中断次数过多导致耗费了大量CPU时间。
DMA方式：在外设和内存之间开辟直接的数据交换通路。
优点：CPU和I/O设备可以并行工作，设备与内存数据交换速度加快，且不需要CPU干预。
缺点：数据传送的方向、存放输入数据的内存起始地址及传送数据的长度等都由CPU控制，
并且每台设备都需要一个DMA控制器，当设备增加时，多个DMA控制器的使用也不经
济。
通道控制方式：I/O通道是专门负责输入/输出的处理机。
优点：解决了I/O操作的独立性和各部件工作的并行性，CPU只需发出I/O指令，通道就能完成相应的I/O操作，并在I/O操作结束时向CPU发出中断信号，将CPU从繁琐的输入/输出操作中解放出来。采用通道技术不仅能实现CPU与通道的并行操作，而且通道与通道之间也能实现并行操作，各通道上的外设也能实现并行操作，从而提高整个系统效率。
缺点：需要更多硬件（通道处理器），因此成本较高。
通道与一般处理器的区别：I/O通道的指令类型单一，没有自己的内存，通道所执行的通道程序放在主机的内存中，也就是说通道与CPU共享内存。
中断处理层的主要任务：进行进程上下文的切换，对处理中断信号源进行测试，读取设备状态和修改进程状态等。
中断过程：（1）唤醒被阻塞的驱动程序过程
          （2）保护被中断过程的CPU环境
          （3）分析中断原因
          （4）进行中断处理
          （5）恢复被中断进程的现场
设备驱动程序的处理过程：（1）将抽象要求转换为具体要求
                        （2）检测I/O请求的合法性
                        （3）读出和检查设备的状态
                        （4）传送必要参数
                        （5）设置工作方式
                        （6）启动I/O设备
中断驱动I/O方式的流程：
 
	I/O控制方式有： 程序直接控制方式 、 中断驱动方式 、 DMA方式 和 通道控制方式 。
	通道的类型有： 字节多路通道 、 数组选择通道 和 数组多路通道 。
	在I/O系统中引入缓冲的原因有： 减少中断次数 、 提高并行性 和 缓解CPU与I/O速度不匹配的矛盾 。
	通道程序解决了I/O操作的独立性和各部件工作的 并行性 ，采用通道技术后，能实现CPU与通道的 并行 操作。
	由 操作系统 启动外围设备不仅可保证安全地使用外围设备，正确地传送信息，而且可减少用户为启动外围设备而必须了解外围设备特性及组织启动等工作，大大方便了用户。实现设备的独立性可采用 逻辑设备表 。
	设备管理的基本任务是： 完成用户提出的I/O请求 ， 提高I/O速度 及 改善I/O设备的利用率 。
	主存储器与外围设备之间的信息传送操作称为 DMA 。
	在对打印机进行I/O控制时，通常采用 中断驱动 方式，对硬盘的I/O控制采用 DMA 方式。
	CPU是怎样与I/O设备进行信息交换的，主要涉及哪些硬件、软件的支持？
答：CPU与I/O设备是通过接口进行信息交换的，一般涉及硬件的是各寄存器，软件是设备驱动程序。
	为什么要在设备管理中引入缓冲技术？操作系统如何实现缓冲技术？
答：引入缓冲的主要原因有：
（1）缓和CPU与I/O设备间速度不匹配的矛盾。
（2）减少对CPU的中断频率，放宽对中断响应时间的限制。
（3）解决数据粒度不匹配的问题。
（4）提高CPU和I/O设备之间的并行性。
根据I/O控制方式，缓冲的实现方法有：
（1）采用专门硬件缓冲器。
（2）在内存划出一个具有n个单元的专用缓冲区，以便存放输入输出的数据。内存缓冲区又称为软件缓冲。
	阐述计算机系统中缓冲的作用和分类。
答：为了缓和CPU和外设之间的矛盾，操作系统引入了单缓冲、双缓冲、循环缓冲以及缓冲池。
    单缓冲：在CPU和外设之间设置了一个缓冲区，当有数据交换时，先把数据发往缓冲区，再冲缓冲区中读数据。
    双缓冲：具有两个缓冲，当一个进程正在往一个缓冲区读数据的时候，操作系统可能正在读或写另外一个缓冲区。
  循环缓冲：具有多个缓冲区的组合，它更加能够缓和CPU和外设之间速度的不匹配。
    缓冲池：既可用于输入又可用于输出的公用缓冲池，在池中设置了多个可供若干个进程共享的缓冲区。
	什么是DMA方式？它与中断方式的主要区别是什么？
答：DMA是直接存储器存取。DMA传输将数据从一个地址空间复制到另外一个地址空间。当CPU初始化这个传输动作，传输动作本身是由DMA控制器来实行和完成。在实现DMA传输时，是由DMA控制器直接掌管总线，因此，存在着一个总线控制权转移问题。即DMA传输前，CPU要把总线控制权交给DMA控制器，而在结束DMA传输后，DMA控制器应立即把总线控制权再交回给CPU。
    它与中断方式的主要区别在于，DMA方式只需要CPU在开始和完成传输时进行干预，其它时候不需要CPU干预。中断驱动方式在每个数据需要传输时中断CPU，而DMA方式则是在所要求传送的一批数据全部传送结束时才中断CPU。中断驱动方式数据传送是在中断处理时由CPU控制完成的，而DMA方式则是在DMA控制器的控制下完成的。
	DMA控制方式与通道控制方式有什么不同？
答：在DMA控制方式中，DMA控制器控制设备和主存之间成批地进程数据交流，而不用CPU干预。这样不但减轻了CPU的负担，而且提高了I/O数据传送速度。这种控制方式应用于块设备的数据传输。
    通道控制方式与DMA控制方式类似，也是一种以内存为中心，实现设备与内存直接交换数据的控制方式。在通道控制方式中，CPU只需发出启动指令，指出通道相应的操作和I/O设备，该指令就可以启动通道并使通道从内存中调出相应的通道程序执行。与DMA相比，通道方式所需的CPU干预更少，并且可以做到一个通道控制多台设备，从而进一步减轻了CPU负担。
	以从I/O设备读入数据为例，请用流程图方式说明程序I/O、DMA传输控制的处理过程。
答：程序I/O方式：							DMA方式：
 
	在设备管理中引入单缓冲，如果从磁盘把一块数据输入到缓冲区中花费的时间为B，把缓冲区中的数据传送到用户区，所花费的时间为M，CPU对数据进行处理的时间为C，则系统对每一块数据的处理时间是多少？要求写出由B、C、M组成的表达式，并说明其中的道理。
答：按题意，可以将操作顺序排列为：I/O1（磁盘到缓冲区）→I/O2（缓冲区到用户区）→CPU。由于I/O1和I/O2之间共享一个单缓冲区，因此一次只能有一个进行操作，所以两者之间的工作是串行的，同样I/O2和CPU之间也是如此。但当I/O2完成操作后，I/O1和CPU之间没有制约关系，可以并行操作。因此，系统对每一块数据的处理时间是：M+C（当C>B时）或M+B（当C<B时）。
	DMA控制器主要由哪些寄存器构成？简述功能。
答：（1）命令/状态寄存器。用于接收从CPU发来的I/O命令、有关控制信息或设备的状态。
    （2）内存地址寄存器MAR。用于存放数据从设备传送到内存的目标地址，或由内存到设备的内存源地址。
    （3）数据寄存器DR。用于暂存从设备到内存或从内存到设备的数据。
    （4）数据计数器DC。存放本次CPU要读或写的字节数。
	为什么说直到出现中断和通道技术后，多道程序概念才变为有用的？
答：多道程序并发执行是指有的程序正在CPU上执行，而另一些程序正在I/O设备上进行传输，即通过CPU操作与外设传输在时间上的重叠必须有中断和通道技术支持，其原因如下：
    （1）通道是一种控制一台或多台外设的硬件机构，它一旦被启动就独立于CPU运行，因而做到了输入/输出操作与CPU并行工作。
    （2）在硬件上引入了中断技术。所谓中断就是在输入/输出结束时，或硬件发生某种故障时，由相应的硬件向CPU发出信号，这时CPU立即停下工作转而处理中断请求，待处理完中断后再继续原来的工作。
    因此，通道技术和中断技术结合起来就可以实现CPU与I/O设备并行工作，即CPU
启动通道传输数据后便去执行其它程序的计算工作，而通道则进行输入/输出操作；
当通道工作结束时，再通过中断机构向CPU发出中断请求，CPU则暂停正在执行的
操作，对出现的中断进行处理，处理完后再继续原来的工作。这样就真正做到了CPU
与I/O设备并行工作，此时多道程序的概念才变为现实。

	磁盘管理与磁盘调度算法：SSTF算法，SCAN算法，CSCAN算法，N-STEP-SCAN算法，FSCAN算法
先来先服务（FCFS）
最短寻道时间优先（SSTF）
扫描算法（SCAN）
循环扫描算法（CSCAN）
SSTF、SCAN、CSCAN几种调度算法中，都可能出现磁臂停留在某处不动的情况，这一现象称为“磁臂粘着”。
N-STEP-SCAN算法：N步SCAN算法是将磁盘请求队列分成若干个长度为N的子队列，磁盘调度将按FCFS算法依次处理这些子队列。而每处理一个队列时又是按SCAN算法，对一个队列处理完后，再处理其它队列。当正在处理某子队列时，如果又出现新的磁盘I/O请求，便将新请求进程放入其它队列，这样就可以避免出现粘着现象。当N值取得很大时，会使N步扫描法的性能接近于SCAN算法的性能；当N=1时，N步SCAN算法便蜕化为FCFS算法。
FSCAN算法：FSCAN算法实质上是N步SCAN算法的简化，即FSCAN只将磁盘请求队列分成两个子队列。一个是由当前所有请求磁盘I/O的进程形成的队列，由磁盘调度按SCAN算法进行处理。另一个是在扫描期间，将新出现的所有请求磁盘I/O的进程放入等待处理的请求队列。这样，所有的新请求都将被推迟到下一次扫描时处理。
	执行一次磁盘输入输出操作所花费的时间包括 寻道时间 、 旋转延迟时间 和 传输时间 。
	磁盘的驱动调度包括 移臂 调度和 旋转 调度部分，其目的是降低 读写磁盘 的总时间。

	设备分配、设备处理、虚拟设备，Spooling系统
设备分配：按照设备类型和相应的分配算法决定将I/O设备分配给哪一个进程。如果在I/O设备和CPU之间还存在着设备控制器和通道，那么还必须分配相应的设备控制器和通道，以保证I/O设备与CPU之间有传递信息的通路。凡未分配到所需设备的进程应放在一个等待队列。
设备处理：设备处理程序用以实现CPU和设备控制器之间的通信。进行I/O操作时，由CPU向设备控制器发出I/O指令，启动设备进行I/O操作；当I/O操作完成时能对设备发来的中断请求作出及时的响应和处理。
	操作系统利用 共享设备 来模拟 独占设备 的工作，为用户提供虚拟设备服务，实现虚拟设备必须要有一定的 硬件和软件 条件为基础，操作系统实现虚拟设备的功能模块是在计算机控制下通过 联机的外围设备同时操作 来实现其功能的，因此也把它称为 SPOOLing 。
	采用SPOOLing技术的计算机系统中，操作员只要启动 预输入 程序工作，就可以把作业存放到 输入井 中等待处理。
	阐述什么是SPOOLING技术。
答：SPOOLING技术是同时联机外围操作技术的简称。它是关于慢速字符设备如何与计算机主机进行数据交换的一种技术，通常又称假脱机技术。在多道程序环境下，利用多道程序中的一道或者两道来模拟脱机输入/输出中的外围控制机的功能，以达到“脱机”输入/输出的目的。利用这种技术可把独占设备转变成共享的虚拟设备，从而提高独占设备的利用率和进程推进速度。
	简述SPOOLING技术是如何模拟脱机外围设备操作的。
答：预输入程序模拟控制输入的外围机，缓输出程序模拟控制输出的外围机，输出井和输入井模拟脱机外围设备操作的两个磁盘。
	按资源分配管理技术，输入输出设备类型可分为哪几类？
答：按资源分配管理的特点，输入输出设备可分为独享设备、共享设备和虚拟设备三类。
    独享设备：不能共享的设备，一段时间只能由一个作业独占。如打印机、读卡机、磁带机等。所有字符型输入输出设备原则上都应是独享设备。
    共享设备：可由若干作业同时共享的设备，如磁盘机等。共享分配技术保证多个进程可以同时方便地直接存取一台共享设备，共享提高了设备的利用率。块设备都是共享设备。
    虚拟设备：利用某种技术把独享设备改造成多台同类型独享设备或共享设备。虚拟分配技术就是利用共享设备去虚拟独享设备，从而使独享设备成为可共享的、快速I/O的设备。实现虚拟分配的最有名的技术是SPOOLing技术，即假脱机技术。
	为什么要引入SPOOLING系统？SPOOLING系统可带来哪些好处？
答：所有字符设备都是独占设备并属于慢速设备，因此，当一个进程在某台字符设备上进行数据交换时，往往要等待较长时间，并且在此进程未释放该设备之前，其它进程不能同时访问该设备，从而使这类设备成为系统的“瓶颈”。另一方面，分配到字符设备的进程，在整个运行期间也并非一直使用设备，利用率较低，从而降低了整个系统的性能。SPOOLING技术正是针对上述问题提出的一种技术。SPOOLING技术的核心思想是利用一台可共享、高速、大容量的块设备来模拟独占设备的操作，使一台独占设备变成多台可并行使用的虚拟设备。SPOOLING系统主要由输入井和输出井、输入缓冲区和输出缓冲区以及输入进程和输出进程3部分组成。在SPOOLING系统中，输出进程将用户要求的数据从输入设备送到输入井，当需要输入数据时，CPU直接从输入井将数据读入内存；输出进程把用户要输出的数据先从内存送到输出井，等输出设备空闲时再将输出井中的数据输出到设备上。
    SPOOLING系统可带来如下好处：
    （1）提高了I/O速度
    （2）将独占设备改造成共享设备
    （3）实现了虚拟设备功能
	为什么要引入设备独立性？如何实现设备独立性？
答：引入设备独立性可使应用程序独立于具体的物理设备。此时，用户用逻辑设备名来申请使用某类物理设备，当系统中有多台该类型的设备时，系统可以将其中的一台分配给请求进程，而不必局限于某一台指定的设备，这样可以显著改善资源的利用率及可适应性。独立性还可以使用户程序独立于设备的类型，如进行输出时，既可用显示终端，也可以用打印机。有了这种适应性，就可以很方便地进行输入/输出重定向。
    为了实现设备独立性，必须在设备驱动程序之上设置一层设备独立性软件，用来执行所有I/O设备的公用操作，并向用户层软件提供统一接口。关键是系统中必须设置一张逻辑设备表（LUT）用来进行逻辑设备到物理设备的映射，其中每个表目中包含逻辑设备名、物理设备名和设备驱动程序入口地址；当应用程序用逻辑设备名请求分配I/O设备时，系统必须为它分配相应的物理设备，并在LUT中建立一个表目，以后进程利用该逻辑设备名请求I/O操作时，便可从LUT中得到物理设备名和驱动程序入口地址。
	用于设备分配的数据结构有哪些？它们之间的关系是什么？
答：用于设备分配的数据结构有：
系统设备表（SDT）、设备控制表（DCT）、控制器控制表（COCT）和通道控制表（CHCT）。
SDT整个系统中只有一张，记录系统中全部设备的情况，是系统范围的数据结构。
每个设备有一张DCT，系统为每一个设备配置一张DCT，以记录本设备的情况。
每个控制器有一张COCT，系统为每一个控制器都设置一张用于记录本控制器情况的COCT。
系统为每个通道配置一张CHCT，以记录通道情况。
SDT中有一个DCT指针，DCT中有一个COCT指针，COCT中有一个CHCT指针，CHCT中有一个COCT指针。

	文件系统
	基本概念：文件和文件系统、目录、文件结构的物理结构和逻辑结构（顺序文件、索引顺序文件、索引文件、HASH文件）
文件：以计算机硬盘为载体存储在计算机上的信息集合。
文件系统：操作系统中负责管理和存储文件信息的软件机构。
文件系统组成：与文件管理有关的软件、被管理的文件以及实施文件管理所需的数据结构。
文件系统的层次结构：
 
文件分为：无结构文件（流式文件）、有结构文件（记录式文件）
用途：系统文件、库文件、用户文件
保护级别：只读文件、读写文件、执行文件、不保护文件
信息流向：输入文件、输出文件、输入输出文件
数据形式：源文件、目标文件、可执行文件
目录：用于标识系统中的文件及其物理地址，供检索时使用的一种数据结构。
	为解决HASH冲突，可采用的方式有： 二维表 、 加位移常量 和 溢出技术 。
	文件系统中设置打开（OPEN）操作的目的是 减少通道压力 和 提高访问效率 。
	文件在文件存储空间的组织方式，成为文件的 物理 结构。
	UNIX系统，使文件描述信息单独形成一个数据结构叫 索引结点 。在文件目录中的每个目录项，仅由 文件名 和 指向该文件i结点的指针 构成。
	文件系统的主要目标是 提高存储空间的利用率 和 减少存取时间 。
	按照组织方式分类文件，可以将文件分为 逻辑文件 和 物理文件 。
	什么是顺序文件、索引文件、索引顺序文件和HASH文件？试说明它们的优点和缺点。
答：顺序文件：指由一系列记录按照某种顺序排列所形成的文件。
优点：当需要对记录进行批量存取时，它的存取效率最高。
缺点：当文件较大时，记录的检索效率较低。
      记录的增加和删除比较困难。
索引文件：索引结构为一个逻辑文件的信息建立一个索引表，索引表中的表目存放文件记录的长度和所在逻辑文件的起始位置，而逻辑文件中不再保存记录的长度信息。索引表本身是一个定长文件，每个逻辑块可以是变长的，索引表和逻辑文件两者构成了索引文件。
优点：可以随机访问，易于文件的增删。
缺点：增加了存储空间开销，索引表查找策略对文件系统效率影响很大。
索引顺序文件：索引顺序文件是顺序文件和索引文件两种形式的结合。索引顺序文件将顺序文件中的所有记录分为若干个组，为顺序文件建立一张索引表，并为每组中的第一个记录在索引表建立一个索引项，其中含有该记录的关键字和指向该记录的指针。索引表中索引项按照关键字顺序排列，索引顺序文件的逻辑文件（主文件）是一个顺序文件，每个分组内部的关键字不必有序排列，但是组与组之间的关键字是有序排列的。
优点：提高了存取的速度。
缺点：需要配置索引表而增加了存储开销。
HASH文件：通过HASH函数建立关键字和相应记录物理地址之间的对应关系，可以直接通过关键字的值找到记录的物理地址，即关键字的值决定了记录的物理地址，这种结构的文件称为HASH文件。
优点：有很高的存取速度。
缺点：因不同关键词的HASH函数值相同而引起冲突。
	文件的物理结构是指一个文件在外存上的存储组织形式，主要有连续结构、链接结构和索引结构三种，请分别简述它们的优缺点。
答：连续结构：在创建文件时需要给文件分配一组连续的盘块。
优点：顺序访问容易、速度快，当文件是定长时可以根据文件起始地址及记录长度进行随机访问。
缺点：文件存储要求连续的存储空间，会产生碎片，也不利于文件的动态扩充。
链接结构：可为文件分配多个不连续的盘块，再通过每个盘块上的链接指针，将同属于一个文件的多个离散的盘块链接成一个链表，由此所形成的物理文件称为链接文件。
优点： 消除了磁盘的外部碎片，提高了外存的利用率。对插入、删除和修改记录
都非常容易。能适应文件的动态增长，无需事先知道文件的大小。
缺点： 只能按照文件的指针链顺序访问，查找效率低，指针信息存放消耗外存空
间。
索引结构：为文件的每个分区单独建立一张索引表，该索引表记录了分配给该文件
的所有块号。
优点：直接访问和顺序访问的速度都比较快，易于文件的增删。
缺点：索引表增加存储空间的开销，索引表的查找策略对文件系统效率影响较大。
	为什么文件系统要具有为文件分配存储空间的能力？
答：要把文件保存到存储介质上时，必须要记住哪些存储空间已经被占用，哪些存储空间是空闲的，文件只能够保存到空闲的空间去，否则会破坏已经保存的信息。
	叙述文件管理系统设置打开文件和关闭文件操作的原因。
答：用户进程存取一个文件，系统首先要检索目录结构，按名查找该文件的文件控制块。打开文件的基本思想是：按指定文件名检索目录结构，把找到的文件控制块读入并保存到内存，此后每次存取该文件时，就无须再执行按名查找过程，可以直接在内存找到文件控制块，从而加快存取速度。文件打开后，可以对文件进行读、写操作。当一个文件不再存取时，需要关闭该文件，释放占用的系统资源，并将文件控制块的内容复制到外存中。这样不但提高了资源利用率，而且保证了数据的安全（对于延迟写的系统）。

	外存分配方法：连续分配、链接分配、索引分配
链接分配分为：隐式链接和显式链接
隐式链接：用于链接物理块的指针隐式地放在每个物理块中。
显式链接：用于链接物理块的指针显式存放在内存的一张链接表中，每个磁盘设置一张链接表，也称文件分配表（FAT）。
	考虑文件系统的外存分配，简述什么是连续分配方式，链接分配方式和索引分配方式。
答：连续分配方式：在创建文件时需要给文件分配一组连续的盘块。
优点：顺序访问容易、速度快，当文件是定长时可以根据文件起始地址及记录长度进行随机访问。
缺点：文件存储要求连续的存储空间，会产生碎片，也不利于文件的动态扩充。
链接分配方式：可为文件分配多个不连续的盘块，再通过每个盘块上的链接指针，将同属于一个文件的多个离散的盘块链接成一个链表，由此所形成的物理文件称为链接文件。
优点： 消除了磁盘的外部碎片，提高了外存的利用率。对插入、删除和修改记录
都非常容易。能适应文件的动态增长，无需事先知道文件的大小。
缺点： 只能按照文件的指针链顺序访问，查找效率低，指针信息存放消耗外存空
间。
索引分配方式：为文件的每个分区单独建立一张索引表，该索引表记录了分配给该文件的所有块号。
优点：直接访问和顺序访问的速度都比较快，易于文件的增删。
缺点：索引表增加存储空间的开销，索引表的查找策略对文件系统效率影响较大。

	目录管理：单级目录、二级目录、多级目录
目录管理的要求：（1）实现“按名存取”
                （2）提高对目录的检索速度
                （3）允许文件共享
                （4）允许文件重名
单级目录：在整个文件系统中只建立一张目录表，每个文件占一个目录项。
实现了“按名存取”，但查找速度慢，不允许重名，不便于实现文件共享。
二级目录：将文件目录分成主文件目录和用户文件目录，系统为每个用户建立一个单独的文件用户目录。
解决了文件重名问题，并可以获得较高的查找速度，但二级目录缺乏灵活性，不能对文件分
类，特别是当用户需要在某些任务上进行合作和访问其它文件时会产生很多问题。
多级目录：将两级目录结构的层次关系加以推广，就形成了多级目录结构，即树形目录结构。
便于对文件分类，层次结构清晰，也能够更有效地进行文件的管理和保护；但在查找一个文
件时，需要按照路径名逐级访问中间节点而增加了磁盘访问次数，进而影响了查询速度。
	简述文件的检索过程。
答：一般文件的检索过程如下：
    （1）由用户提供的路径和文件名，在目录文件中找到该文件目录。
（2）由文件目录（文件控制块）中所描述的信息查找到该文件存储的物理位置。
（3）根据文件存放的物理结构及其相应的存取方式，访问该文件。

	文件存储空间的管理技术：位示图、空闲链表、索引
空闲表：空闲表法属于连续分配方式，为每个文件分配一块连续的存储空间，系统为外存上的所有空闲区建立一张空闲盘块表，表项包括第一个空闲块号、物理块号和空闲块数目等。
空闲链表：（1）空闲块链表是将文件存储设备上的所有空闲块链接在一起，形成一条空闲
块链，并设置一个头指针指向空闲块链的第一个物理块。
（2）空闲盘区链表是将磁盘上的所有空闲盘区链接在一起，形成一条空闲盘区链，在每个盘区上除了含有用于指示下一个空闲盘区的指针外，还应有能指明本盘区大小的信息。
	位示图可以用来指示磁盘存储空间的使用情况，一个磁盘组的分块确定后，根据可分配的总块数决定位示图由多少个字组成，位示图中的每一位与一块对应，“1”状态表示相应块 已分配 ，“0”状态表示该块 空闲 。
	简述利用位示图进行文件存储空间管理的思想。这种方法的优缺点是什么？
答：若磁盘块空闲，则用“0”表示，若磁盘块已分配，则用“1”表示，从而得到一张位示图表，反映了所有磁盘块的信息。
优点：很容易找到一个或一组相邻接的空闲块。
缺点：整个磁盘的位示图文件比较大，在磁盘空闲块较少时，搜索空闲块要花费一些时间。
